{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LibVQ \n",
    "Here is a demo to use LibVQ to generate PQ for [SPTAG](https://github.com/microsoft/SPTAG).\n",
    "\n",
    "## Install\n",
    "```bash\n",
    "git clone https://github.com/staoxiao/LibVQ.git\n",
    "cd LibVQ\n",
    "pip install .\n",
    "```\n",
    "\n",
    "## Overview\n",
    "There are tow modes to train the PQ:\n",
    "- **LearnableIndex**: train the codebooks with fixed embeddings\n",
    "- **LearnableIndexWithEncoder**: jointly train the codebooks and query/doc encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare\n",
    "### Download data\n",
    "We take the MSMARCO dataset as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-12 12:41:33--  https://rocketqa.bj.bcebos.com/corpus/marco.tar.gz\n",
      "Resolving rocketqa.bj.bcebos.com (rocketqa.bj.bcebos.com)... 103.235.46.61, 2409:8c04:1001:1002:0:ff:b001:368a\n",
      "Connecting to rocketqa.bj.bcebos.com (rocketqa.bj.bcebos.com)|103.235.46.61|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1140510742 (1.1G) [application/x-gzip]\n",
      "Saving to: ‘marco.tar.gz’\n",
      "\n",
      "marco.tar.gz        100%[===================>]   1.06G  9.43MB/s    in 1m 45s  \n",
      "\n",
      "2022-06-12 12:43:20 (10.3 MB/s) - ‘marco.tar.gz’ saved [1140510742/1140510742]\n",
      "\n",
      "--2022-06-12 12:45:02--  https://msmarco.blob.core.windows.net/msmarcoranking/collectionandqueries.tar.gz\n",
      "Resolving msmarco.blob.core.windows.net (msmarco.blob.core.windows.net)... 20.150.34.4\n",
      "Connecting to msmarco.blob.core.windows.net (msmarco.blob.core.windows.net)|20.150.34.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1057717952 (1009M) [application/gzip]\n",
      "Saving to: ‘collectionandqueries.tar.gz’\n",
      "\n",
      "collectionandquerie 100%[===================>]   1009M  35.0MB/s    in 53s     \n",
      "\n",
      "2022-06-12 12:45:57 (19.0 MB/s) - ‘collectionandqueries.tar.gz’ saved [1057717952/1057717952]\n",
      "\n",
      "collection.tsv\n",
      "qrels.dev.small.tsv\n",
      "qrels.train.tsv\n",
      "queries.dev.small.tsv\n",
      "queries.dev.tsv\n",
      "queries.eval.small.tsv\n",
      "queries.eval.tsv\n",
      "queries.train.tsv\n"
     ]
    }
   ],
   "source": [
    "! bash download_data.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 864/864 [29:10<00:00,  2.03s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [01:03<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocess_dir = './data/preprocessed_dataset'\n",
    "embedding_dir = './Results/ARG'\n",
    "max_query_length = 32\n",
    "max_doc_length = 256\n",
    "\n",
    "# preprocess\n",
    "from LibVQ.dataset.preprocess import preprocess_data\n",
    "from transformers import AutoTokenizer\n",
    "preprocess_data(data_dir='./data/dataset/',\n",
    "                output_dir=preprocess_dir,\n",
    "                text_tokenizer=AutoTokenizer.from_pretrained('Shitao/msmarco_query_encoder'),\n",
    "                add_cls_tokens=True,\n",
    "                max_doc_length=max_doc_length,\n",
    "                max_query_length=max_query_length,\n",
    "                workers_num=64)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from LibVQ.inference import get_embeddings\n",
    "from LibVQ.models import Encoder, TransformerModel\n",
    "\n",
    "# Load encoder\n",
    "query_encoder = TransformerModel.from_pretrained('Shitao/msmarco_query_encoder')\n",
    "doc_encoder = TransformerModel.from_pretrained('Shitao/msmarco_doc_encoder')\n",
    "text_encoder = Encoder(query_encoder, doc_encoder)\n",
    "emb_size = query_encoder.encoder.config.hidden_size\n",
    "\n",
    "# generate embeddings\n",
    "doc_embeddings, dev_query, train_query = get_embeddings(data_dir=preprocess_dir,\n",
    "               encoder=text_encoder,\n",
    "               max_doc_length=max_doc_length,\n",
    "               max_query_length=max_query_length,\n",
    "               output_dir=embedding_dir,\n",
    "               batch_size=10240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev-rels.tsv: 7437it [00:00, 784296.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# convert to the format for SPTAG\n",
    "import struct, os\n",
    "from LibVQ.dataset.dataset import load_rel\n",
    "\n",
    "os.makedirs('input_for_SPTAG', exist_ok=True)\n",
    "with open(os.path.join('input_for_SPTAG', 'doc_vectors.bin'), 'wb') as f:\n",
    "    f.write(struct.pack('ii', doc_embeddings.shape[0], doc_embeddings.shape[1] ))\n",
    "    f.write(doc_embeddings.tobytes())\n",
    "\n",
    "with open(os.path.join('input_for_SPTAG', 'query_vectors.bin'), 'wb') as f:\n",
    "    f.write(struct.pack('ii', dev_query.shape[0], dev_query.shape[1] ))\n",
    "    f.write(dev_query.tobytes())\n",
    "\n",
    "data = load_rel('./data/preprocessed_dataset/dev-rels.tsv')\n",
    "max_len = max([len(x) for x in data.values()])\n",
    "with open('input_for_SPTAG/test_rels.txt', 'w') as f:\n",
    "    for i in range(len(data)):\n",
    "        ns = list(data[i])\n",
    "        ns = ns + [-1]*(max_len-len(ns))\n",
    "        f.write(' '.join([str(x) for x in ns]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of PQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings:\n",
    "index_method = 'opq'\n",
    "ivf_centers_num = -1\n",
    "subvector_num = 32\n",
    "subvector_bits = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faiss PQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "from LibVQ.utils import save_to_SPTAG_binary_file\n",
    "from LibVQ.base_index import FaissIndex\n",
    "\n",
    "\n",
    "# Creat Faiss index\n",
    "faiss.omp_set_num_threads(32)\n",
    "index = FaissIndex(index_method=index_method,\n",
    "                   emb_size=len(doc_embeddings[0]),\n",
    "                   ivf_centers_num=ivf_centers_num,\n",
    "                   subvector_num=subvector_num,\n",
    "                   subvector_bits=subvector_bits,\n",
    "                   dist_mode='ip')\n",
    "\n",
    "index.fit(doc_embeddings)\n",
    "index.add(doc_embeddings)\n",
    "\n",
    "os.makedirs('input_for_SPTAG/OPQ', exist_ok=True)\n",
    "save_to_SPTAG_binary_file(index, save_dir='input_for_SPTAG/OPQ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distill-VQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "from torch.optim import AdamW\n",
    "from LibVQ.dataset.dataset import load_rel, write_rel\n",
    "from LibVQ.learnable_index import LearnableIndex\n",
    "\n",
    "faiss.omp_set_num_threads(32)\n",
    "\n",
    "doc_embeddings_file = os.path.join(embedding_dir, 'docs.memmap')\n",
    "query_embeddings_file = os.path.join(embedding_dir, 'train-queries.memmap')\n",
    "init_index_file = os.path.join(embedding_dir, f'{index_method}_ivf{ivf_centers_num}_pq{subvector_num}x{subvector_bits}.index')\n",
    "save_ckpt_dir = f'./saved_ckpts/distill-VQ/'\n",
    "\n",
    "# Load embeddings of train queries\n",
    "train_query_embeddings = np.memmap(query_embeddings_file, dtype=np.float32, mode=\"r\")\n",
    "train_query_embeddings = train_query_embeddings.reshape(-1, emb_size)\n",
    "\n",
    "\n",
    "# Create Index\n",
    "learnable_index = LearnableIndex(index_method=index_method,\n",
    "                                 init_index_file=init_index_file,\n",
    "                                 doc_embeddings=doc_embeddings,\n",
    "                                 ivf_centers_num=ivf_centers_num,\n",
    "                                 subvector_num=subvector_num,\n",
    "                                 subvector_bits=subvector_bits)\n",
    "\n",
    "    \n",
    "'''\n",
    "If there is not relevance data, you can set the rel_file/rel_data to None, and it will automatically generate the data for training.\n",
    "You also can manually generate the data as following:\n",
    "        '''\n",
    "if not os.path.exists(os.path.join(embedding_dir, 'train-virtual_rel.tsv')):\n",
    "    from LibVQ.dataset.preprocess import generate_virtual_traindata\n",
    "    generate_virtual_traindata(\n",
    "            doc_embeddings,\n",
    "            train_query,\n",
    "            output_dir = embedding_dir,\n",
    "            use_gpu=False,\n",
    "            topk= 400,\n",
    "            index_method = 'opq',\n",
    "            subvector_num=32,\n",
    "            subvector_bits=8,\n",
    "            dist_mode='ip')\n",
    "\n",
    "# distill with no label data\n",
    "learnable_index.fit_with_multi_gpus(rel_file=os.path.join(embedding_dir, 'train-virtual_rel.tsv'),\n",
    "                                    neg_file=os.path.join(embedding_dir,\n",
    "                                                          f\"train-queries-virtual_hardneg.pickle\"),\n",
    "                                    query_embeddings_file=query_embeddings_file,\n",
    "                                    doc_embeddings_file=doc_embeddings_file,\n",
    "                                    emb_size=emb_size,\n",
    "                                    per_query_neg_num=1,\n",
    "                                    checkpoint_path=save_ckpt_dir,\n",
    "                                    logging_steps=100,\n",
    "                                    per_device_train_batch_size=512,\n",
    "                                    loss_weight={'encoder_weight': 0.0, 'pq_weight': 1.0,\n",
    "                                                 'ivf_weight': 0.0},\n",
    "                                    lr_params={'encoder_lr': 0.0, 'pq_lr': 1e-4, 'ivf_lr': 0.0},\n",
    "                                    loss_method='distill',\n",
    "                                    epochs=30)\n",
    "\n",
    "\n",
    "os.makedirs('input_for_SPTAG/LearnableIndex', exist_ok=True)\n",
    "save_to_SPTAG_binary_file(learnable_index, save_dir='input_for_SPTAG/LearnableIndex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distill-VQ with Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LibVQ.learnable_index import LearnableIndexWithEncoder\n",
    "\n",
    "from transformers import BertModel\n",
    "\n",
    "\n",
    "save_ckpt_dir = f'./saved_ckpts/distill-VQ-Encoder/'\n",
    "\n",
    "learnable_index_with_encoder = LearnableIndexWithEncoder(index_method=index_method,\n",
    "                                 encoder=text_encoder,\n",
    "                                 init_index_file=init_index_file,\n",
    "                                 doc_embeddings=doc_embeddings,\n",
    "                                 ivf_centers_num=ivf_centers_num,\n",
    "                                 subvector_num=subvector_num,\n",
    "                                 subvector_bits=subvector_bits)\n",
    "\n",
    "\n",
    "learnable_index_with_encoder.fit(rel_data=os.path.join(embedding_dir, 'train-virtual_rel.tsv'),\n",
    "                                neg_data=os.path.join(embedding_dir,\n",
    "                                                      f\"train-queries-virtual_hardneg.pickle\"),\n",
    "                                query_data_dir=preprocess_dir,\n",
    "                                max_query_length=max_query_length,\n",
    "                                query_embeddings=query_embeddings_file,\n",
    "                                doc_embeddings=doc_embeddings_file,\n",
    "                                emb_size=emb_size,\n",
    "                                per_query_neg_num=1,\n",
    "                                checkpoint_path=save_ckpt_dir,\n",
    "                                logging_steps=100,\n",
    "                                per_device_train_batch_size=512,\n",
    "                                loss_weight={'encoder_weight': 1.0, 'pq_weight': 1.0,\n",
    "                                             'ivf_weight': 0.0},\n",
    "                                lr_params={'encoder_lr': 1e-5, 'pq_lr': 1e-4, 'ivf_lr': 0.0},\n",
    "                                loss_method='distill',\n",
    "                                epochs=10)\n",
    "\n",
    "os.makedirs('input_for_SPTAG/LearnableIndexWithEncoder', exist_ok=True)\n",
    "\n",
    "new_query_embeddings = learnable_index_with_encoder.encode(data_dir=preprocess_dir,\n",
    "                                              prefix='dev-queries',\n",
    "                                              max_length=max_query_length,\n",
    "                                              output_dir='input_for_SPTAG/LearnableIndexWithEncoder',\n",
    "                                              batch_size=8196,\n",
    "                                              is_query=True,\n",
    "                                              return_vecs=True\n",
    "                                              )\n",
    "    \n",
    "\n",
    "save_to_SPTAG_binary_file(learnable_index, save_dir='input_for_SPTAG/LearnableIndexWithEncoder')\n",
    "with open(os.path.join('input_for_SPTAG/LearnableIndexWithEncoder', 'new_query.bin'), 'wb') as f:\n",
    "    f.write(struct.pack('ii', new_query_embeddings.shape[0], new_query_embeddings.shape[1] ))\n",
    "    f.write(new_query_embeddings.tobytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use PQ in SPTAG Index\n",
    "\n",
    "## Create SPTAG index\n",
    "- Install the SPTAG following [link](https://github.com/microsoft/SPTAG).\n",
    "- Update the paths in create.ini\n",
    "  - VectorPath: the path to quantized_doc.bin,e.g., ./input_for_SPTAG/LearnableIndex/quantized__vectors.bin\n",
    "  - QuantizerFilePath: the path to parameters (rotate and codebooks), e.g., ./input_for_SPTAG/LearnableIndex/index_parameters.bin\n",
    "  - IndexDirectory: the path to save the index\n",
    "- Run: ./ssdservering create.ini\n",
    "\n",
    "## Search via SPTAG\n",
    "- Update the paths in search.ini\n",
    "  - VectorPath: default to None. Given the path to uncompressed doc embeddings, the index will rerank candidates based on the uncompressed embeddings.\n",
    "  - QuantizerFilePath: the path to parameters (rotate and codebooks), e.g., ./input_for_SPTAG/LearnableIndex/index_parameters.bin\n",
    "  - IndexDirectory: the path to save the index\n",
    "  - QueryPath/WarmupPath: the path to query embeddings. Noted that use the new query embeddings if you use the LearnIndexWithEncoder, e.g.,./input_for_SPTAG/LearnableIndexWithEncoder/new_query.bin \n",
    "- Run: ./ssdservering search.ini\n",
    "\n",
    "\n",
    "## Results\n",
    "\n",
    "Methods | Recall@10 |\n",
    "------- | ------- |\n",
    "OPQ | 0.541595 |\n",
    "LearnableIndex | 0.559169 |\n",
    "LearnableIndexWithEncoder | 0.580540 |"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "interpreter": {
   "hash": "955b5dbf1c9568fcdca6427b82ed9dd3b5652756bab72d537c2112a7dd2607f3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython2",
  "version": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}